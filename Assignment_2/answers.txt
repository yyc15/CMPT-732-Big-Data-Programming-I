Student Id: 301436160
1.	In the WikipediaPopular class, it would be much more interesting to find the page that is most popular, not just the view count (as we did with Spark). What would be necessary to modify your class to do this? (You don't have to actually implement it.)

Ans: Create a PairWritable class for IntWritable and String. Modify the mapper class output from IntWritable to the newly created PairWritable type. Initiate a new pair variable with PairWritable type. Assign the number of view and page title to the pair variable. In the context.wirte function, replace the number of view (original IntWritable variable) with the new pair variable.
After that, modify the reducer class output from IntWritable to the newly created PairWritable type. Modify the result variable with PairWritable type. Assign maximum value and the corresponding page name into the result variable.

2.	An RDD has many methods: it can do many more useful tricks than were at hand with MapReduce. Write a sentence or two to explain the difference between .map and .flatMap. Which is more like the MapReduce concept of mapping?

Ans: .map function produces one output for one input value which is one-to-one mapping and it is only used for mapping. On the other hand, .flatMap function produces an arbitrary number of values as output for each input value which is one-to-many mapping and it can perform mapping and flattening.
The .flatmap is more like the MapReduce concept of mapping since it spawns one map task for each InputSplit generated by the InputFormat for the job.

3.	Do the same for .reduce and .reduceByKey. Which is more like the MapReduce concept of reducing?

Ans: The .reduce function for aggregation. It is used to aggregate elements in a dataset such as  calculate sum, minimum and maximum of elements. On the other hand, . reduceByKey is a function for transformation. It is used to merge and associate the values for each key. The .reduceByKey is more like the MapReduce because MapReduce will undergo mapping, shuffling and reducing which consolidates the elements in dataset and returns a single output value.


4.	When finding popular Wikipedia pages, the maximum number of page views is certainly unique, but the most popular page might be a tie. What would your improved Python implementation do if there were two pages with the same highest number of page views in an hour? What would be necessary to make your code find all of the pages views the maximum number of times? (Again, you don't have to actually implement this.)

Ans: The function of the reducer has to be modified to return a list page names which has the number of page views that equals to the maximum page view per hour. In returning the page name of the dataset, the string variable should be change to a list of page name.

